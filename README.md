# Bilingual-SQL-Coder

A comprehensive Text-to-SQL framework supporting bilingual (English & Chinese) datasets with training, data processing, deployment, and evaluation capabilities.

---

### ğŸ˜®æ–°å‘å¸ƒï¼
- æƒé‡å·²ç»å¼€æºåˆ°ğŸ‘Hugging Faceï¼šhttps://huggingface.co/GodRayyyy/Bilingual-SQL-Coder

---

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

## English

### Overview

Bilingual-SQL-Coder is an end-to-end solution for Text-to-SQL tasks, supporting:
- ğŸ§¹ **Data Processing**: Bilingual translation, data cleaning, and synthesis
- ğŸ“ **Model Training**: SFT (Supervised Fine-Tuning) with LoRA/DoRA on large language models
- ğŸš€ **Application**: Web-based SQL generation interface
- ğŸ“Š **Evaluation**: Comprehensive evaluation metrics and data generation

### Project Structure

```
Bilingual-SQL-Coder/
â”œâ”€â”€ data_expert/           # Bilingual data processing expert
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ translator.py      # Bilingual translation
â”‚   â”œâ”€â”€ synthesizer.py     # Data synthesis
â”‚   â”œâ”€â”€ data_cleaner.py    # Data cleaning
â”‚   â””â”€â”€ eval_generator.py  # Evaluation data generation
â”œâ”€â”€ sft/                   # Supervised Fine-Tuning
â”‚   â”œâ”€â”€ train_only_text_DoRA_all.sh
â”‚   â”œâ”€â”€ inference_only_text.py
â”‚   â””â”€â”€ data/
â”œâ”€â”€ application/           # Web UI & API
â”‚   â”œâ”€â”€ app.py            # Streamlit web interface
â”‚   â””â”€â”€ config/
â”œâ”€â”€ evaluation/           # Evaluation tools
â”‚   â”œâ”€â”€ run_full_evaluation.py
â”‚   â”œâ”€â”€ universal_evaluation.py
â”‚   â””â”€â”€ structured_sql_converter.py
â””â”€â”€ requirements.txt      # Project dependencies
```

### Quick Start

#### 1. Environment Setup

```bash
# Clone repository
git clone https://github.com/GodRayyy/Bilingual-SQL-Coder.git
cd Bilingual-SQL-Coder

# Install dependencies
pip install -r requirements.txt
```

#### 2. Data Processing (data_expert)

The data_expert module provides comprehensive data processing:

```bash
cd data_expert

# Set API Key for Qwen API
export DASHSCOPE_API_KEY="sk-your-key-here"

# Translate data to bilingual format
python main.py translate --data spider_train.json --schema tables.json

# Synthesize data
python main.py synthesize --domains "enterprise sales" "student grades" --n 20

# Clean data
python main.py clean --data dirty_data.json

# Generate evaluation data
python main.py eval --data train.json --schema tables.json

# Run complete pipeline
python main.py run --data spider_train.json --schema tables.json
```

**Features:**
- ğŸŒ Bilingual translation (English â†” Chinese)
- ğŸ”§ Data synthesis based on Schema
- ğŸ§¹ SQL syntax error detection and fixing
- ğŸ“Š Evaluation data generation
- ğŸ¯ Real-world data augmentation (typos, colloquial language)

#### 3. Model Training (sft)

Train models using LoRA/DoRA on Qwen models:

```bash
cd sft

# Modify training configuration in train_only_text_DoRA_all.sh
# Set your model path, data path, and training parameters

# Run training
bash train_only_text_DoRA_all.sh
```

**Configuration options in the shell script:**
- `CUDA_VISIBLE_DEVICES`: GPU selection
- `MODEL_ID`: Base model path
- `TRAIN_DATA`: Training data path
- `EVAL_DATA`: Evaluation data path

#### 4. Inference

Generate SQL from natural language questions:

```bash
cd sft

# Inference with trained model
python inference_only_text.py \
  --model_type tuned \
  --checkpoint_dir ./path/to/checkpoint \
  --output_file predictions.json
```

#### 5. Web Application (application)

Deploy the interactive web interface:

```bash
cd application

# Run Streamlit app
streamlit run app.py --server.port 8501 --server.address 0.0.0.0
```

Access the interface at: http://localhost:8501

#### 6. Evaluation (evaluation)

Evaluate model performance:

```bash
cd evaluation

# Run full evaluation
python run_full_evaluation.py \
  --prediction_file predictions.json \
  --gold_file dev_gold.sql
```

### Supported Models

- **Qwen3-4B-Instruct**: Lightweight, fast inference
- **Qwen3-8B-Instruct**: Balanced performance and speed
- **Qwen3-VL-8B-Instruct**: Vision-Language support (for future features)

### Dataset Support

- **Spider**: English database-agnostic text-to-SQL benchmark
- **CSpider**: Chinese version of Spider
- **Custom Datasets**: Support for custom database schemas

### API Key Configuration

For data processing features requiring LLM API:

1. Visit [Alibaba Cloud DashScope](https://dashscope.aliyuncs.com/)
2. Create an account and enable DashScope service
3. Generate API Key
4. Set environment variable: `export DASHSCOPE_API_KEY="sk-your-key"`

### Citation

If you use Bilingual-SQL-Coder in your research, please cite:

```bibtex
@software{bilingual_sql_coder,
  title={Bilingual-SQL-Coder: A Text-to-SQL Framework},
  author={Tianyu Gao, Deyang Wang, Yiwen Ma},
  year={2025},
  url={https://github.com/GodRayyy/Bilingual-SQL-Coder}
}
```

### License

MIT License - see LICENSE file for details

### Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ä¸­æ–‡

### é¡¹ç›®ä»‹ç»

Bilingual-SQL-Coder æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„Text-to-SQLä»»åŠ¡è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒï¼š
- ğŸ§¹ **æ•°æ®å¤„ç†**ï¼šåŒè¯­ç¿»è¯‘ã€æ•°æ®æ¸…æ´—å’Œåˆæˆ
- ğŸ“ **æ¨¡å‹è®­ç»ƒ**ï¼šåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šè¿›è¡ŒSFTï¼ˆæœ‰ç›‘ç£å¾®è°ƒï¼‰
- ğŸš€ **åº”ç”¨éƒ¨ç½²**ï¼šåŸºäºWebçš„SQLç”Ÿæˆç•Œé¢
- ğŸ“Š **æ•ˆæœè¯„ä¼°**ï¼šå®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡å’Œæ•°æ®ç”Ÿæˆ

### é¡¹ç›®ç»“æ„

```
Bilingual-SQL-Coder/
â”œâ”€â”€ data_expert/           # åŒè¯­æ•°æ®å¤„ç†ä¸“å®¶
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ translator.py      # åŒè¯­ç¿»è¯‘
â”‚   â”œâ”€â”€ synthesizer.py     # æ•°æ®åˆæˆ
â”‚   â”œâ”€â”€ data_cleaner.py    # æ•°æ®æ¸…æ´—
â”‚   â””â”€â”€ eval_generator.py  # è¯„æµ‹æ•°æ®ç”Ÿæˆ
â”œâ”€â”€ sft/                   # æœ‰ç›‘ç£å¾®è°ƒ
â”‚   â”œâ”€â”€ train_only_text_DoRA_all.sh
â”‚   â”œâ”€â”€ inference_only_text.py
â”‚   â””â”€â”€ data/
â”œâ”€â”€ application/           # Webç•Œé¢ & API
â”‚   â”œâ”€â”€ app.py            # Streamlitç½‘é¡µç•Œé¢
â”‚   â””â”€â”€ config/
â”œâ”€â”€ evaluation/           # è¯„ä¼°å·¥å…·
â”‚   â”œâ”€â”€ run_full_evaluation.py
â”‚   â”œâ”€â”€ universal_evaluation.py
â”‚   â””â”€â”€ structured_sql_converter.py
â””â”€â”€ requirements.txt      # é¡¹ç›®ä¾èµ–
```

### å¿«é€Ÿå¼€å§‹

#### 1. ç¯å¢ƒé…ç½®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/GodRayyy/Bilingual-SQL-Coder.git
cd Bilingual-SQL-Coder

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 2. æ•°æ®å¤„ç† (data_expert)

ä½¿ç”¨data_expertæ¨¡å—è¿›è¡Œæ•°æ®å¤„ç†ï¼š

```bash
cd data_expert

# è®¾ç½®é€šä¹‰åƒé—®API Key
export DASHSCOPE_API_KEY="sk-your-key-here"

# ç¿»è¯‘æ•°æ®ä¸ºåŒè¯­æ ¼å¼
python main.py translate --data spider_train.json --schema tables.json

# åˆæˆæ•°æ®
python main.py synthesize --domains "ä¼ä¸šé”€å”®" "å­¦ç”Ÿæˆç»©" --n 20

# æ¸…æ´—æ•°æ®
python main.py clean --data dirty_data.json

# ç”Ÿæˆè¯„æµ‹æ•°æ®
python main.py eval --data train.json --schema tables.json

# è¿è¡Œå®Œæ•´Pipeline
python main.py run --data spider_train.json --schema tables.json
```

**ä¸»è¦åŠŸèƒ½ï¼š**
- ğŸŒ åŒè¯­ç¿»è¯‘ï¼ˆè‹±æ–‡ â†” ä¸­æ–‡ï¼‰
- ğŸ”§ åŸºäºSchemaçš„æ•°æ®åˆæˆ
- ğŸ§¹ SQLè¯­æ³•é”™è¯¯æ£€æµ‹å’Œä¿®å¤
- ğŸ“Š è¯„æµ‹æ•°æ®ç”Ÿæˆ
- ğŸ¯ çœŸå®åœºæ™¯æ•°æ®å¢å¼ºï¼ˆé”™åˆ«å­—ã€å£è¯­åŒ–ç­‰ï¼‰

#### 3. æ¨¡å‹è®­ç»ƒ (sft)

ä½¿ç”¨LoRA/DoRAåœ¨Qwenæ¨¡å‹ä¸Šè¿›è¡Œå¾®è°ƒï¼š

```bash
cd sft

# ä¿®æ”¹train_only_text_DoRA_all.shä¸­çš„é…ç½®
# è®¾ç½®æ¨¡å‹è·¯å¾„ã€æ•°æ®è·¯å¾„å’Œè®­ç»ƒå‚æ•°

# å¼€å§‹è®­ç»ƒ
bash train_only_text_DoRA_all.sh
```

**shellè„šæœ¬ä¸­çš„é…ç½®é€‰é¡¹ï¼š**
- `CUDA_VISIBLE_DEVICES`: GPUè®¾å¤‡é€‰æ‹©
- `MODEL_ID`: åŸºç¡€æ¨¡å‹è·¯å¾„
- `TRAIN_DATA`: è®­ç»ƒæ•°æ®è·¯å¾„
- `EVAL_DATA`: è¯„ä¼°æ•°æ®è·¯å¾„

#### 4. æ¨¡å‹æ¨ç†

ä»è‡ªç„¶è¯­è¨€é—®é¢˜ç”ŸæˆSQLï¼š

```bash
cd sft

# ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†
python inference_only_text.py \
  --model_type tuned \
  --checkpoint_dir ./path/to/checkpoint \
  --output_file predictions.json
```

#### 5. Webåº”ç”¨ (application)

éƒ¨ç½²äº¤äº’å¼Webç•Œé¢ï¼š

```bash
cd application

# è¿è¡ŒStreamlitåº”ç”¨
streamlit run app.py --server.port 8501 --server.address 0.0.0.0
```

è®¿é—®åœ°å€: http://localhost:8501

#### 6. æ•ˆæœè¯„ä¼° (evaluation)

è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼š

```bash
cd evaluation

# è¿è¡Œå®Œæ•´è¯„ä¼°
python run_full_evaluation.py \
  --prediction_file predictions.json \
  --gold_file dev_gold.sql
```

### æ”¯æŒçš„æ¨¡å‹

- **Qwen3-4B-Instruct**: è½»é‡çº§ï¼Œæ¨ç†é€Ÿåº¦å¿«
- **Qwen3-8B-Instruct**: æ€§èƒ½ä¸é€Ÿåº¦å¹³è¡¡
- **Qwen3-VL-8B-Instruct**: è§†è§‰-è¯­è¨€æ”¯æŒï¼ˆæœªæ¥åŠŸèƒ½ï¼‰

### æ”¯æŒçš„æ•°æ®é›†

- **Spider**: è‹±æ–‡æ•°æ®åº“æ— å…³Text-to-SQLåŸºå‡†
- **CSpider**: Spiderçš„ä¸­æ–‡ç‰ˆæœ¬
- **è‡ªå®šä¹‰æ•°æ®é›†**: æ”¯æŒè‡ªå®šä¹‰æ•°æ®åº“Schema

### API Key é…ç½®

å¯¹äºéœ€è¦LLM APIçš„æ•°æ®å¤„ç†åŠŸèƒ½ï¼š

1. è®¿é—® [é˜¿é‡Œäº‘DashScope](https://dashscope.aliyuncs.com/)
2. åˆ›å»ºè´¦æˆ·å¹¶å¼€é€šDashScopeæœåŠ¡
3. ç”ŸæˆAPI Key
4. è®¾ç½®ç¯å¢ƒå˜é‡: `export DASHSCOPE_API_KEY="sk-your-key"`

### å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†Bilingual-SQL-Coderï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{bilingual_sql_coder,
  title={Bilingual-SQL-Coder: A Text-to-SQL Framework},
  author={Tianyu Gao, Deyang Wang, Yiwen Ma},
  year={2025},
  url={https://github.com/GodRayyy/Bilingual-SQL-Coder}
}
```

### License

MIT License - è¯¦è§LICENSEæ–‡ä»¶

### è´¡çŒ®

æ¬¢è¿æäº¤Pull Requestï¼

