#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Text2SQL å¤šæ•°æ®é›†è¯„æµ‹ç³»ç»Ÿ - ä¸»è¯„æµ‹è„šæœ¬
===========================================

åŠŸèƒ½ï¼š
    å¯¹Text2SQLå¾®è°ƒæ¨¡å‹è¿›è¡Œå…¨é¢è¯„æµ‹ï¼Œæ”¯æŒ7ä¸ªä¸»æµæ•°æ®é›†

æ”¯æŒçš„æ•°æ®é›†ï¼š
    è‹±æ–‡: Spider, Bird, WikiSQL
    ä¸­æ–‡: CSpider, Chase, DuSQL, AntSQL

è¯„æµ‹æµç¨‹ï¼š
    1. åŠ è½½å¾®è°ƒæ¨¡å‹ï¼ˆæˆ–åŸºç¡€æ¨¡å‹ï¼‰
    2. å¯¹æ¯ä¸ªæ•°æ®é›†ç”ŸæˆSQLé¢„æµ‹
    3. è¯„æµ‹ç”Ÿæˆçš„SQLï¼ˆExact Match + Execution Accuracyï¼‰
    4. è¾“å‡ºæ¯ä¸ªæ•°æ®é›†å’Œæ•´ä½“çš„è¯„åˆ†

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # è¯„æµ‹æ‰€æœ‰æ•°æ®é›†
    python run_full_evaluation.py --model_type tuned --checkpoint_dir /path/to/checkpoint --datasets all
    
    # åªè¯„æµ‹Spiderå’ŒCSpider
    python run_full_evaluation.py --model_type tuned --checkpoint_dir /path/to/checkpoint --datasets Spider,CSpider
    
    # ä½¿ç”¨åŸºç¡€æ¨¡å‹è¯„æµ‹
    python run_full_evaluation.py --model_type base --datasets all

æ³¨æ„äº‹é¡¹ï¼š
    - WikiSQLå’ŒAntSQLçš„SQLæ˜¯ç»“æ„åŒ–æ ¼å¼ï¼Œæš‚æ—¶åªæ”¯æŒæ¨ç†ï¼Œä¸æ”¯æŒè‡ªåŠ¨è¯„æµ‹
    - Chaseéœ€è¦è‡ªåŠ¨ç”Ÿæˆgold SQLæ–‡ä»¶ï¼ˆä»å¤šè½®å¯¹è¯ä¸­æå–ç¬¬ä¸€è½®ï¼‰
    - è¯„æµ‹éœ€è¦GPUæ”¯æŒ
"""

import os
import sys
import json
import argparse
import torch
import re
import pandas as pd
from io import StringIO
from tqdm import tqdm
from peft import PeftModel, PeftConfig
from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM

# å°è¯•å¯¼å…¥ swiftï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ transformers çš„ set_seed
try:
    from swift.utils import seed_everything
except ImportError:
    from transformers import set_seed as seed_everything

# ================= é…ç½®è·¯å¾„ =================
BASE_DIR = "/data0/dywang/Llm/Text2Sql"
DATA_COLLECTED_DIR = os.path.join(BASE_DIR, "data_collected")
EVAL_SCRIPT_DIR = os.path.join(DATA_COLLECTED_DIR, "spider/eval")
BASE_MODEL_ID = "/data0/tygao/models/Qwen3-4B-Instruct-2507"

# æ•°æ®é›†é…ç½®å­—å…¸ - æ”¯æŒ7ä¸ªæ•°æ®é›†
DATASET_CONFIGS = {
    # ========== è‹±æ–‡æ•°æ®é›† ==========
    "Spider": {
        "language": "en",
        "dev_file": os.path.join(DATA_COLLECTED_DIR, "spider/dev.json"),
        "tables_file": os.path.join(DATA_COLLECTED_DIR, "spider/tables.json"),
        "db_dir": os.path.join(DATA_COLLECTED_DIR, "spider/database"),
        "gold_sql": os.path.join(DATA_COLLECTED_DIR, "spider/gt_sql/dev_gold.sql"),
        "has_evaluator": True  # ä½¿ç”¨é€šç”¨è¯„æµ‹å™¨
    },
    "Bird": {
        "language": "en",
        "dev_file": os.path.join(DATA_COLLECTED_DIR, "Bird/dev/dev.json"),
        "tables_file": os.path.join(DATA_COLLECTED_DIR, "Bird/dev/dev_tables.json"),
        "db_dir": os.path.join(DATA_COLLECTED_DIR, "Bird/dev/dev_databases"),
        "gold_sql": os.path.join(DATA_COLLECTED_DIR, "Bird/dev/dev.sql"),
        "has_evaluator": True  # ä½¿ç”¨é€šç”¨è¯„æµ‹å™¨
    },
    "WikiSQL": {
        "language": "en",
        "dev_file": os.path.join(DATA_COLLECTED_DIR, "WikiSQL/data/dev.jsonl"),
        "tables_file": os.path.join(DATA_COLLECTED_DIR, "WikiSQL/data/dev.tables.jsonl"),
        "db_dir": None,  # WikiSQLä½¿ç”¨å•ä¸ªSQLiteæ–‡ä»¶ï¼Œä¸é€‚åˆé€šç”¨è¯„æµ‹å™¨çš„executionæµ‹è¯•
        "gold_sql": None,  # å°†åŠ¨æ€ç”Ÿæˆåˆ°evaluationç›®å½•
        "has_evaluator": True,  # ä½¿ç”¨é€šç”¨è¯„æµ‹å™¨ï¼ˆéœ€è¦å…ˆè½¬æ¢ç»“æ„åŒ–SQLï¼‰
        "is_jsonl": True,
        "needs_gold_generation": True,  # éœ€è¦ä»ç»“æ„åŒ–SQLç”Ÿæˆgold SQL
        "gold_generation_type": "wikisql"  # æŒ‡å®šç”Ÿæˆç±»å‹
    },
    
    # ========== ä¸­æ–‡æ•°æ®é›† ==========
    "CSpider": {
        "language": "zh",
        "dev_file": os.path.join(DATA_COLLECTED_DIR, "CSpider/dev.json"),
        "tables_file": os.path.join(DATA_COLLECTED_DIR, "CSpider/tables.json"),
        "db_dir": os.path.join(DATA_COLLECTED_DIR, "CSpider/database"),
        "gold_sql": os.path.join(DATA_COLLECTED_DIR, "CSpider/dev_gold.sql"),
        "has_evaluator": True  # ä½¿ç”¨é€šç”¨è¯„æµ‹å™¨
    },
    "Chase": {
        "language": "zh",
        "dev_file": os.path.join(DATA_COLLECTED_DIR, "chase/data/dev.json"),
        "tables_file": os.path.join(DATA_COLLECTED_DIR, "chase/data/tables.json"),
        "db_dir": None,  # å°†åŠ¨æ€åˆ›å»º
        "gold_sql": None,  # å°†åŠ¨æ€ç”Ÿæˆåˆ°evaluationç›®å½•
        "has_evaluator": True,  # ä½¿ç”¨é€šç”¨è¯„æµ‹å™¨
        "is_multi_turn": True,  # Chase æ˜¯å¤šè½®å¯¹è¯æ ¼å¼
        "needs_gold_generation": True,  # éœ€è¦ç”Ÿæˆgold SQL
        "needs_db_building": True,  # éœ€è¦ä»JSONæ„å»ºæ•°æ®åº“
        "db_type": "chase"  # æ•°æ®åº“ç±»å‹
    },
    "DuSQL": {
        "language": "zh",
        "dev_file": os.path.join(DATA_COLLECTED_DIR, "DuSQL/dev.json"),
        "tables_file": os.path.join(DATA_COLLECTED_DIR, "DuSQL/db_schema.json"),
        "db_dir": "/data0/tygao/classes/text2sql/evaluation/temp_databases/dusql_databases",  # ä½¿ç”¨å·²æ„å»ºçš„æ•°æ®åº“
        "db_schema_file": os.path.join(DATA_COLLECTED_DIR, "DuSQL/db_schema.json"),
        "db_content_file": os.path.join(DATA_COLLECTED_DIR, "DuSQL/db_content.json"),
        "gold_sql": os.path.join(DATA_COLLECTED_DIR, "DuSQL/gold_dev.sql"),
        "has_evaluator": True,  # ä½¿ç”¨é€šç”¨è¯„æµ‹å™¨
        "needs_db_building": False,  # æ•°æ®åº“å·²å­˜åœ¨ï¼Œä¸éœ€è¦é‡æ–°æ„å»º
        "db_type": "dusql"  # æ•°æ®åº“ç±»å‹
    },
    "AntSQL": {
        "language": "zh",
        "dev_file": os.path.join(DATA_COLLECTED_DIR, "antsql1/antsql1_dev.jsonl"),
        "tables_file": os.path.join(DATA_COLLECTED_DIR, "antsql1/antsql1_fundTable.xlsx"),
        "db_dir": None,  # AntSQLæ²¡æœ‰æ•°æ®åº“æ–‡ä»¶ï¼Œåªæ”¯æŒExact Matchè¯„æµ‹
        "gold_sql": None,  # å°†åŠ¨æ€ç”Ÿæˆåˆ°evaluationç›®å½•
        "has_evaluator": True,  # ä½¿ç”¨é€šç”¨è¯„æµ‹å™¨ï¼ˆéœ€è¦å…ˆè½¬æ¢ç»“æ„åŒ–SQLï¼‰
        "is_jsonl": True,
        "needs_gold_generation": True,  # éœ€è¦ä»ç»“æ„åŒ–SQLç”Ÿæˆgold SQL
        "gold_generation_type": "antsql"  # æŒ‡å®šç”Ÿæˆç±»å‹
    }
}

# å¯¼å…¥é€šç”¨è¯„æµ‹è„šæœ¬
try:
    from universal_evaluation import UniversalEvaluator
    print("âœ… æˆåŠŸå¯¼å…¥é€šç”¨è¯„æµ‹æ¨¡å—")
except ImportError:
    print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥é€šç”¨è¯„æµ‹æ¨¡å—ï¼Œéƒ¨åˆ†è¯„æµ‹åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    UniversalEvaluator = None

# å¯¼å…¥JSONæ•°æ®åº“æ„å»ºå·¥å…·
try:
    from json_db_builder import JSONDatabaseBuilder
    print("âœ… æˆåŠŸå¯¼å…¥JSONæ•°æ®åº“æ„å»ºæ¨¡å—")
except ImportError:
    print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥JSONæ•°æ®åº“æ„å»ºæ¨¡å—ï¼ŒDuSQLå’ŒChaseçš„executionè¯„æµ‹å¯èƒ½ä¸å¯ç”¨")
    JSONDatabaseBuilder = None

# å¯¼å…¥ç»“æ„åŒ–SQLè½¬æ¢å·¥å…·
try:
    from structured_sql_converter import StructuredSQLConverter
    print("âœ… æˆåŠŸå¯¼å…¥ç»“æ„åŒ–SQLè½¬æ¢æ¨¡å—")
except ImportError:
    print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥ç»“æ„åŒ–SQLè½¬æ¢æ¨¡å—ï¼ŒWikiSQLå’ŒAntSQLçš„è¯„æµ‹å¯èƒ½ä¸å¯ç”¨")
    StructuredSQLConverter = None

# ================= è¾…åŠ©å‡½æ•° =================

def load_tables(tables_path):
    """
    åŠ è½½æ•°æ®åº“ Schema ä¿¡æ¯ï¼Œå¹¶å°†å…¶æ•´ç†ä¸ºæ˜“äºæŸ¥è¯¢çš„å­—å…¸æ ¼å¼ã€‚
    æ”¯æŒå¤šç§æ ¼å¼ï¼šSpideræ ¼å¼JSONã€WikiSQL JSONLã€DuSQLæ ¼å¼ã€Excel
    """
    print(f"Loading tables from {tables_path}...")
    
    schema_map = {}
    
    # å¤„ç† Excel æ–‡ä»¶ (AntSQL)
    if tables_path.endswith('.xlsx') or tables_path.endswith('.xls'):
        try:
            df = pd.read_excel(tables_path)
            cols = df.columns.tolist()
            col_str = ", ".join([str(c) for c in cols])
            schema_map['antsql_default'] = f"Table fund_table, columns = [{col_str}]"
            return schema_map
        except Exception as e:
            print(f"Warning: Failed to load Excel file: {e}")
            return schema_map
    
    # å¤„ç† JSONL æ–‡ä»¶ (WikiSQL)
    if tables_path.endswith('.jsonl'):
        try:
            with open(tables_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        item = json.load(StringIO(line))
                        table_id = item.get('id', item.get('table_id', ''))
                        if 'header' in item:
                            cols_str = ", ".join(item['header'])
                            schema_map[table_id] = f"Table {table_id}, columns = [{cols_str}]"
            return schema_map
        except Exception as e:
            print(f"Warning: Failed to load JSONL file: {e}")
            return schema_map
    
    # å¤„ç†æ ‡å‡† JSON æ–‡ä»¶
    with open(tables_path, 'r', encoding='utf-8') as f:
        tables_data = json.load(f)
    
    # å¤„ç† DuSQL ç‰¹æ®Šæ ¼å¼
    if isinstance(tables_data, dict) and 'db_id' not in (tables_data if isinstance(tables_data, dict) else tables_data[0] if tables_data else {}):
        # DuSQL æ ¼å¼: {db_id: {table_info}}
        for db_id, db_info in tables_data.items():
            if 'table_names' in db_info and 'column_names' in db_info:
                table_names = db_info['table_names']
                column_names = db_info['column_names']
                
                tables_dict = {}
                for idx, t_name in enumerate(table_names):
                    tables_dict[idx] = {'name': t_name, 'cols': []}
                
                for col_info in column_names:
                    if isinstance(col_info, list) and len(col_info) >= 2 and col_info[0] >= 0:
                        tables_dict[col_info[0]]['cols'].append(col_info[1])
                
                lines = []
                for t_idx, info in tables_dict.items():
                    col_str = ", ".join(info['cols'])
                    lines.append(f"Table {info['name']}, columns = [{col_str}]")
                schema_map[db_id] = "\n".join(lines)
        return schema_map
    
    # å¤„ç†æ ‡å‡† Spider æ ¼å¼
    for db in tables_data:
        db_id = db.get('db_id', db.get('database_id'))
        if not db_id:
            continue
        
        table_names = db.get('table_names_original', db.get('table_names'))
        column_names = db.get('column_names_original', db.get('column_names'))
        
        if not table_names or not column_names:
            continue

        tables_dict = {} 
        for idx, t_name in enumerate(table_names):
            tables_dict[idx] = {'name': t_name, 'cols': []}
            
        for col_idx, col_info in enumerate(column_names):
            if isinstance(col_info, list) and len(col_info) >= 2:
                table_idx, col_name = col_info[0], col_info[1]
                if table_idx >= 0:
                    tables_dict[table_idx]['cols'].append(col_name)
        
        schema_lines = []
        for table_idx, info in tables_dict.items():
            t_name = info['name']
            c_str = ", ".join(info['cols'])
            schema_lines.append(f"Table {t_name}, columns = [{c_str}]")
            
        schema_str = "\n".join(schema_lines)
        schema_map[db_id] = schema_str
        
    return schema_map

def find_latest_checkpoint(checkpoint_dir):
    """æ”¯æŒç›´æ¥æŒ‡å®šcheckpointç›®å½• + é€‚é….safetensorsæ ¼å¼LoRAæƒé‡"""
    if not os.path.exists(checkpoint_dir):
        raise FileNotFoundError(f"Checkpointç›®å½•ä¸å­˜åœ¨: {checkpoint_dir}")
    
    required_files = ['adapter_config.json', 'adapter_model.safetensors']
    has_lora_files = all(os.path.exists(os.path.join(checkpoint_dir, f)) for f in required_files)
    
    if has_lora_files:
        print(f"âœ… éªŒè¯é€šè¿‡ï¼šä¼ å…¥ç›®å½•æ˜¯æœ‰æ•ˆLoRA checkpoint")
        return checkpoint_dir
    
    subdirs = [os.path.join(checkpoint_dir, d) for d in os.listdir(checkpoint_dir) if os.path.isdir(os.path.join(checkpoint_dir, d))]
    checkpoints = [d for d in subdirs if 'checkpoint' in d.lower()]
    
    if not checkpoints:
        raise FileNotFoundError(f"âŒ é”™è¯¯ï¼šä¼ å…¥ç›®å½•æ— æ•ˆæˆ–æœªæ‰¾åˆ°checkpointå­ç›®å½•: {checkpoint_dir}")
    
    latest_ckpt = max(checkpoints, key=os.path.getmtime)
    print(f"âœ… ä»çˆ¶ç›®å½•æ‰¾åˆ°æœ€æ–°checkpointï¼š{latest_ckpt}")
    return latest_ckpt

# ================= æ¨ç†é€»è¾‘ =================

def generate_gold_sql_for_chase(dev_file, output_gold_file):
    """ä»Chaseçš„dev.jsonç”Ÿæˆgold SQLæ–‡ä»¶ï¼ˆåªå–ç¬¬ä¸€è½®å¯¹è¯ï¼‰"""
    print(f"æ­£åœ¨ä¸ºChaseç”Ÿæˆgold SQLæ–‡ä»¶...")
    with open(dev_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    gold_sqls = []
    for item in data:
        if 'interaction' in item and isinstance(item['interaction'], list) and len(item['interaction']) > 0:
            first_turn = item['interaction'][0]
            sql = first_turn.get('query', first_turn.get('sql', ''))
            gold_sqls.append(sql)
        else:
            gold_sqls.append('')
    
    with open(output_gold_file, 'w', encoding='utf-8') as f:
        for sql in gold_sqls:
            f.write(sql + '\n')
    print(f"âœ… Chase gold SQLå·²ç”Ÿæˆ: {output_gold_file}")
    return output_gold_file

def generate_gold_sql_from_structured(dev_file, tables_file, output_gold_file, generation_type):
    """ä»ç»“æ„åŒ–SQLç”Ÿæˆgold SQLæ–‡ä»¶ï¼ˆWikiSQLå’ŒAntSQLï¼‰"""
    if StructuredSQLConverter is None:
        print("âŒ é”™è¯¯ï¼šç»“æ„åŒ–SQLè½¬æ¢æ¨¡å—æœªåŠ è½½")
        return None
    
    converter = StructuredSQLConverter()
    
    try:
        if generation_type == 'wikisql':
            converter.convert_wikisql_file(dev_file, tables_file, output_gold_file)
        elif generation_type == 'antsql':
            converter.convert_antsql_file(dev_file, tables_file, output_gold_file)
        else:
            print(f"âŒ é”™è¯¯ï¼šæœªçŸ¥çš„ç”Ÿæˆç±»å‹: {generation_type}")
            return None
        
        return output_gold_file
    except Exception as e:
        print(f"âŒ ç”Ÿæˆgold SQLå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def load_dev_data(dev_file, is_jsonl=False, is_multi_turn=False):
    """åŠ è½½å¼€å‘é›†æ•°æ®ï¼Œæ”¯æŒJSONå’ŒJSONLæ ¼å¼"""
    with open(dev_file, 'r', encoding='utf-8') as f:
        if is_jsonl:
            data = []
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
        else:
            data = json.load(f)
    
    # å¦‚æœæ˜¯å¤šè½®å¯¹è¯æ ¼å¼ï¼Œåªå–ç¬¬ä¸€è½®ï¼ˆæˆ–å±•å¼€æ‰€æœ‰è½®æ¬¡ï¼‰
    if is_multi_turn:
        expanded_data = []
        for item in data:
            if 'interaction' in item and isinstance(item['interaction'], list):
                # åªå–ç¬¬ä¸€è½®
                first_turn = item['interaction'][0]
                expanded_item = {
                    'db_id': item.get('db_id', ''),
                    'question': first_turn.get('utterance', first_turn.get('question', '')),
                    'query': first_turn.get('query', first_turn.get('sql', ''))
                }
                expanded_data.append(expanded_item)
            else:
                expanded_data.append(item)
        return expanded_data
    
    return data

def run_inference(model_type, checkpoint_dir, output_file, dataset_name, dataset_config):
    """ç»Ÿä¸€çš„æ¨ç†å‡½æ•°ï¼Œæ”¯æŒæ‰€æœ‰æ•°æ®é›†"""
    seed_everything(42)
    
    language = dataset_config.get('language', 'en')
    dev_file = dataset_config['dev_file']
    tables_file = dataset_config['tables_file']
    is_jsonl = dataset_config.get('is_jsonl', False)
    is_multi_turn = dataset_config.get('is_multi_turn', False)
    
    print(f"\n=== å¼€å§‹æ¨ç† [{dataset_name}] ({language.upper()}) ===")
    print(f"åŸºåº§æ¨¡å‹è·¯å¾„ï¼š{BASE_MODEL_ID}")
    print(f"æ¨¡å‹ç±»å‹ï¼š{model_type}")
    if model_type == 'tuned':
        print(f"LoRA checkpointç›®å½•ï¼š{checkpoint_dir}")
    
    # æ¨¡å‹åŠ è½½é…ç½®
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=False,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
        bnb_4bit_use_double_quant=False,
    )
    model_kwargs = {
        'device_map': 'auto',
        'dtype': torch.bfloat16,
        'quantization_config': bnb_config,
        'trust_remote_code': True,
        'low_cpu_mem_usage': True
    }

    print("\n=== åŠ è½½æ¨¡å‹ ===")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)
    
    if model_type == 'base':
        model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_ID, **model_kwargs)
        print("âœ… åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ")
    else:
        if not checkpoint_dir:
            raise ValueError("âŒ ä½¿ç”¨tunedæ¨¡å¼å¿…é¡»æŒ‡å®šLoRAæƒé‡ç›®å½•")
            
        ckpt_path = find_latest_checkpoint(checkpoint_dir)
        print(f"LoRAæƒé‡è·¯å¾„ï¼š{ckpt_path}")
        
        peft_config = PeftConfig.from_pretrained(ckpt_path)
        model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_ID, **model_kwargs)
        model = PeftModel.from_pretrained(
            model,
            ckpt_path,
            device_map='auto',
            dtype=torch.bfloat16,
            trust_remote_code=True
        )
        print("âœ… å¾®è°ƒæ¨¡å‹ï¼ˆåŸºåº§+LoRAï¼‰åŠ è½½å®Œæˆ")

    # å‡†å¤‡æ•°æ®
    print(f"åŠ è½½æ•°æ®åº“è¡¨ç»“æ„ï¼š{tables_file}")
    schema_map = load_tables(tables_file)
    print(f"åŠ è½½å¼€å‘é›†æ•°æ®ï¼š{dev_file}")
    dev_data = load_dev_data(dev_file, is_jsonl=is_jsonl, is_multi_turn=is_multi_turn)
    
    predictions = []
    print(f"\nå¼€å§‹ç”ŸæˆSQL... (å…± {len(dev_data)} æ¡)")
    
    for item in tqdm(dev_data, desc="ç”ŸæˆSQL"):
        db_id = item.get('db_id', item.get('database_id', item.get('table_id', '')))
        question = item.get('question', item.get('question_text', ''))
        
        # ç‰¹æ®Šå¤„ç†ï¼šWikiSQLä½¿ç”¨table_idï¼ŒAntSQLä½¿ç”¨é»˜è®¤db
        if not db_id or db_id == '':
            if 'table_id' in item:
                db_id = item['table_id']
            elif dataset_name == 'AntSQL':
                db_id = 'antsql_default'
            elif dataset_name == 'Chase' and not db_id:
                # Chaseå¯èƒ½ç¼ºå°‘db_idï¼Œä»ç¬¬ä¸€ä¸ªå¯ç”¨çš„schemaå–
                if schema_map:
                    db_id = list(schema_map.keys())[0]
        
        if not question:
            predictions.append("SELECT * FROM T")
            continue
        
        if db_id not in schema_map:
            # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„schemaï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„
            if schema_map:
                db_id = list(schema_map.keys())[0]
            else:
                predictions.append("SELECT * FROM T")
                continue
            
        schema_context = schema_map[db_id]
        
        # æ ¹æ®è¯­è¨€é€‰æ‹©ä¸åŒçš„ Prompt
        if language == "zh":
            # ä¸­æ–‡ Prompt
            system_content = "ä½ æ˜¯ä¸€åä¸“ä¸šçš„SQLæ•°æ®åˆ†æå¸ˆã€‚" \
                             "è¯·æ ¹æ®ç»™å®šçš„æ•°æ®åº“è¡¨ç»“æ„ï¼ˆSchemaï¼‰å’Œç”¨æˆ·æå‡ºçš„è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œ" \
                             "ç”Ÿæˆä¸€å¥æœ‰æ•ˆçš„SQLæŸ¥è¯¢è¯­å¥ã€‚ä¸è¦æä¾›ä»»ä½•è§£é‡Šï¼Œåªè¾“å‡ºSQLä»£ç ã€‚"
            user_content = f"æ•°æ®åº“è¡¨ç»“æ„ (Database Schema):\n{schema_context}\n\né—®é¢˜ (Question): {question}\n\nSQL:"
        else:
            # è‹±æ–‡ Prompt
            system_content = "You are a professional SQL data analyst. " \
                             "Given a database schema and a natural language question, " \
                             "generate a valid SQL query. Do not provide any explanation, only the SQL."
            user_content = f"Database Schema:\n{schema_context}\n\nQuestion: {question}\n\nSQL:"
        
        messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_content}
        ]
        
        text_prompt = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        inputs = tokenizer(
            text_prompt,
            return_tensors="pt",
            truncation=True,
            max_length=4096
        )
        
        input_ids = inputs['input_ids'].to(model.device)
        attention_mask = inputs['attention_mask'].to(model.device)

        with torch.no_grad():
            generated_ids = model.generate(
                input_ids=input_ids,
                attention_mask=attention_mask,
                max_new_tokens=512,
                pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id,
                temperature=0.01,
                do_sample=False,
            )
        
        input_len = input_ids.shape[1]
        output_ids = generated_ids[0][input_len:]
        response = tokenizer.decode(output_ids, skip_special_tokens=True)
        
        cleaned_sql = response.strip()
        if "```sql" in cleaned_sql:
            cleaned_sql = cleaned_sql.split("```sql")[1].split("```")[0].strip()
        elif "```" in cleaned_sql:
            cleaned_sql = cleaned_sql.split("```")[0].strip()
        cleaned_sql = cleaned_sql.replace('\n', ' ')
        
        predictions.append(cleaned_sql)
    
    print(f"\næ¨ç†å®Œæˆï¼å…±ç”Ÿæˆ {len(predictions)} æ¡SQLè¯­å¥")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for sql in predictions:
            f.write(sql + '\n')
    print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°ï¼š{output_file}")
    
    return len(predictions)

# ================= è¯„æµ‹é€»è¾‘ =================

def parse_evaluation_output(output_text):
    """è§£æè¯„æµ‹è„šæœ¬çš„è¾“å‡ºï¼Œæå–å…³é”®æŒ‡æ ‡"""
    results = {}
    
    # æå– Exact Match
    em_match = re.search(r'exact[_ ]?match.*?:\s*([\d.]+)', output_text, re.IGNORECASE)
    if em_match:
        results['exact_match'] = float(em_match.group(1))
    
    # æå– Execution Accuracy
    exec_match = re.search(r'(?:execution|exec).*?(?:accuracy|score).*?:\s*([\d.]+)', output_text, re.IGNORECASE)
    if exec_match:
        results['execution_accuracy'] = float(exec_match.group(1))
    
    # æå–éš¾åº¦çº§åˆ«åˆ†æ•°
    for level in ['easy', 'medium', 'hard', 'extra']:
        level_match = re.search(rf'{level}.*?:\s*([\d.]+)', output_text, re.IGNORECASE)
        if level_match:
            results[level] = float(level_match.group(1))
    
    return results

def run_evaluation(gold_file, pred_file, db_dir, tables_file, etype, dataset_name="Spider"):
    """è¿è¡Œå•ä¸ªæ•°æ®é›†çš„è¯„æµ‹å¹¶è¿”å›ç»“æœï¼ˆä½¿ç”¨é€šç”¨è¯„æµ‹å™¨ï¼‰"""
    print(f"\n{'='*60}")
    print(f"å¼€å§‹è¿è¡Œ {dataset_name} è¯„æµ‹...")
    print(f"{'='*60}")
    
    if UniversalEvaluator is None:
        print("âŒ é”™è¯¯ï¼šé€šç”¨è¯„æµ‹æ¨¡å—æœªåŠ è½½")
        return {}
    
    print(f"Gold SQL: {gold_file if gold_file else 'N/A (åªè®¡ç®—Execution Accuracy)'}")
    print(f"Pred SQL: {pred_file}")
    print(f"Database: {db_dir}")
    print(f"Tables: {tables_file}")
    print(f"Eval Type: {etype}\n")
    
    # åˆ›å»ºè¯„æµ‹å™¨å¹¶æ‰§è¡Œè¯„æµ‹
    evaluator = UniversalEvaluator(dataset_name=dataset_name)
    results = evaluator.evaluate(
        pred_file=pred_file,
        gold_file=gold_file,  # å¯ä»¥ä¸ºNone
        db_dir=db_dir,
        tables_file=tables_file  # ä¼ å…¥tablesæ–‡ä»¶ç”¨äºåŠ è½½å¤–é”®æ˜ å°„
    )
    
    # æ‰“å°ç»“æœ
    evaluator.print_results(results)
    
    return results

# ================= ä¸»ç¨‹åº =================

def main():
    parser = argparse.ArgumentParser(description="Text2Sql æ•´åˆè¯„æµ‹è„šæœ¬ (æ”¯æŒ 7 ä¸ªæ•°æ®é›†)")
    
    # æ¨ç†å‚æ•°
    parser.add_argument("--model_type", type=str, choices=['base', 'tuned'], default='tuned', help="æ¨¡å‹ç±»å‹: base æˆ– tuned")
    parser.add_argument("--checkpoint_dir", type=str, default=None, help="LoRAå¾®è°ƒæƒé‡ç›®å½• (tunedæ¨¡å¼å¿…å¡«)")
    parser.add_argument("--skip_inference", action="store_true", help="è·³è¿‡æ¨ç†ï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰çš„è¾“å‡ºæ–‡ä»¶è¿›è¡Œè¯„æµ‹")
    parser.add_argument("--datasets", type=str, default="Spider,CSpider", help="è¦æµ‹è¯•çš„æ•°æ®é›†ï¼Œé€—å·åˆ†éš” (æ”¯æŒ: Spider,CSpider,Bird,WikiSQL,Chase,DuSQL,AntSQL æˆ– all)")
    
    # è¯„æµ‹å‚æ•°
    parser.add_argument("--etype", type=str, default="all", choices=['all', 'exec', 'match'], help="è¯„æµ‹ç±»å‹")
    parser.add_argument("--output_dir", type=str, default="/data0/tygao/classes/text2sql/evaluation", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # è§£æè¦æµ‹è¯•çš„æ•°æ®é›†
    if args.datasets.lower() == 'all':
        datasets_to_test = list(DATASET_CONFIGS.keys())
    else:
        datasets_to_test = [ds.strip() for ds in args.datasets.split(',')]
    
    # éªŒè¯æ•°æ®é›†åç§°
    invalid_datasets = [ds for ds in datasets_to_test if ds not in DATASET_CONFIGS]
    if invalid_datasets:
        print(f"âŒ é”™è¯¯ï¼šæ— æ•ˆçš„æ•°æ®é›†åç§°: {', '.join(invalid_datasets)}")
        print(f"æ”¯æŒçš„æ•°æ®é›†: {', '.join(DATASET_CONFIGS.keys())}")
        sys.exit(1)
    
    # ç”Ÿæˆæ¨¡å‹æ ‡è¯†ç¬¦ï¼Œç”¨äºåŒºåˆ†ä¸åŒæ¨¡å‹çš„è¾“å‡ºæ–‡ä»¶
    if args.model_type == 'base':
        model_identifier = 'base'
    else:
        # ä»checkpointè·¯å¾„æå–æ¨¡å‹æ ‡è¯†
        if args.checkpoint_dir:
            # æå–checkpointç›®å½•åä½œä¸ºæ ‡è¯†ï¼ˆå¦‚ checkpoint-2700ï¼‰
            ckpt_name = os.path.basename(args.checkpoint_dir.rstrip('/'))
            model_identifier = f"tuned_{ckpt_name}"
        else:
            model_identifier = 'tuned'
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Text2SQL å¤šæ•°æ®é›†è¯„æµ‹ç³»ç»Ÿ")
    print(f"{'='*80}")
    print(f"å°†è¦æµ‹è¯•çš„æ•°æ®é›†: {', '.join(datasets_to_test)}")
    print(f"æ¨¡å‹ç±»å‹: {args.model_type}")
    print(f"æ¨¡å‹æ ‡è¯†: {model_identifier}")
    if args.model_type == 'tuned':
        print(f"Checkpoint: {args.checkpoint_dir}")
    print(f"{'='*80}\n")
    
    # åˆå§‹åŒ–JSONæ•°æ®åº“æ„å»ºå™¨
    db_builder = None
    if JSONDatabaseBuilder is not None:
        # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦æ„å»ºæ•°æ®åº“çš„æ•°æ®é›†
        needs_building = any(DATASET_CONFIGS[ds].get('needs_db_building', False) 
                            for ds in datasets_to_test if ds in DATASET_CONFIGS)
        if needs_building:
            db_builder = JSONDatabaseBuilder(temp_dir=os.path.join(args.output_dir, "temp_databases"))
            print(f"âœ… JSONæ•°æ®åº“æ„å»ºå™¨å·²åˆå§‹åŒ–")
    
    # å­˜å‚¨è¯„æµ‹ç»“æœ
    results = {}
    
    # å¾ªç¯å¤„ç†æ¯ä¸ªæ•°æ®é›†
    for dataset_name in datasets_to_test:
        config = DATASET_CONFIGS[dataset_name]
        
        print(f"\n{'='*80}")
        emoji = "ğŸ”µ" if config['language'] == 'en' else "ğŸŸ¢"
        print(f"{emoji} å¤„ç† {dataset_name} æ•°æ®é›† ({config['language'].upper()})")
        print(f"{'='*80}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(config['dev_file']):
            print(f"âš ï¸  è­¦å‘Š: å¼€å‘é›†æ–‡ä»¶ä¸å­˜åœ¨: {config['dev_file']}")
            print(f"   è·³è¿‡ {dataset_name} æ•°æ®é›†\n")
            continue
        
        # å¦‚æœéœ€è¦ç”Ÿæˆgold SQLæ–‡ä»¶
        if config.get('needs_gold_generation', False):
            # Gold SQLç”Ÿæˆåˆ°evaluationç›®å½•ä»¥é¿å…æƒé™é—®é¢˜
            gold_sql_path = os.path.join(args.output_dir, f"gold_{dataset_name.lower()}.sql")
            config['gold_sql'] = gold_sql_path  # æ›´æ–°é…ç½®
            
            if not os.path.exists(gold_sql_path):
                print(f"\nğŸ’¡ {dataset_name} éœ€è¦ç”Ÿæˆgold SQLæ–‡ä»¶...")
                try:
                    generation_type = config.get('gold_generation_type', '')
                    if dataset_name == 'Chase':
                        generate_gold_sql_for_chase(config['dev_file'], gold_sql_path)
                    elif generation_type in ['wikisql', 'antsql']:
                        generate_gold_sql_from_structured(
                            config['dev_file'],
                            config['tables_file'],
                            gold_sql_path,
                            generation_type
                        )
                    else:
                        print(f"âš ï¸  è­¦å‘Šï¼šæœªçŸ¥çš„ç”Ÿæˆç±»å‹: {generation_type}")
                except Exception as e:
                    print(f"âŒ ç”Ÿæˆgold SQLå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"âœ… Gold SQLæ–‡ä»¶å·²å­˜åœ¨: {gold_sql_path}")
        
        # å¦‚æœéœ€è¦ä»JSONæ„å»ºæ•°æ®åº“
        if config.get('needs_db_building', False) and db_builder is not None:
            db_type = config.get('db_type', '')
            print(f"\nğŸ”¨ {dataset_name} éœ€è¦ä»JSONæ„å»ºæ•°æ®åº“...")
            
            try:
                if db_type == 'dusql':
                    db_dir = db_builder.build_dusql_database(
                        db_schema_file=config['db_schema_file'],
                        db_content_file=config['db_content_file']
                    )
                    config['db_dir'] = db_dir  # æ›´æ–°é…ç½®
                    print(f"âœ… DuSQLæ•°æ®åº“å·²æ„å»º: {db_dir}")
                elif db_type == 'chase':
                    db_dir = db_builder.build_chase_database(
                        tables_file=config['tables_file']
                    )
                    config['db_dir'] = db_dir  # æ›´æ–°é…ç½®
                    print(f"âœ… Chaseæ•°æ®åº“å·²æ„å»º: {db_dir}")
            except Exception as e:
                print(f"âŒ æ„å»ºæ•°æ®åº“å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«æ¨¡å‹æ ‡è¯†ï¼Œé¿å…è¦†ç›–ï¼‰
        output_file = os.path.join(args.output_dir, f"pred_{dataset_name.lower()}_{model_identifier}.sql")
        
        # 1. æ¨ç†é˜¶æ®µ
        if not args.skip_inference:
            try:
                num_samples = run_inference(
                    model_type=args.model_type,
                    checkpoint_dir=args.checkpoint_dir,
                    output_file=output_file,
                    dataset_name=dataset_name,
                    dataset_config=config
                )
                print(f"âœ… {dataset_name} æ¨ç†å®Œæˆï¼Œç”Ÿæˆ {num_samples} æ¡SQL")
            except Exception as e:
                print(f"âŒ {dataset_name} æ¨ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
        else:
            print(f"è·³è¿‡æ¨ç†ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶: {output_file}")
            if not os.path.exists(output_file):
                print(f"âŒ é”™è¯¯: æ–‡ä»¶ {output_file} ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œè¯„æµ‹ã€‚")
                continue
        
        # 2. è¯„æµ‹é˜¶æ®µï¼ˆä»…å¯¹æœ‰è¯„æµ‹è„šæœ¬çš„æ•°æ®é›†ï¼‰
        if config.get('has_evaluator', False):
            # æ£€æŸ¥gold SQLæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            gold_file = config.get('gold_sql')
            use_gold_file = gold_file and os.path.exists(gold_file)
            
            if not use_gold_file:
                if gold_file:
                    print(f"\nâš ï¸  è­¦å‘Š: Gold SQLæ–‡ä»¶ä¸å­˜åœ¨: {gold_file}")
                print(f"âš ï¸  å°†è·³è¿‡Exact Matchè¯„æµ‹ï¼Œåªè®¡ç®—Execution Accuracy")
                gold_file = None  # è®¾ç½®ä¸ºNoneä»¥è·³è¿‡exact match
            
            try:
                result = run_evaluation(
                    gold_file=gold_file,
                    pred_file=output_file,
                    db_dir=config['db_dir'],
                    tables_file=config['tables_file'],
                    etype=args.etype,
                    dataset_name=dataset_name
                )
                results[dataset_name] = result
            except Exception as e:
                print(f"âŒ {dataset_name} è¯„æµ‹å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                results[dataset_name] = None
        else:
            print(f"\nğŸ’¡ {dataset_name} æš‚æ— å®˜æ–¹è¯„æµ‹è„šæœ¬ï¼Œå·²ç”Ÿæˆé¢„æµ‹SQL: {output_file}")
            results[dataset_name] = {"status": "inference_only", "output_file": output_file}
    
    # ========== æ±‡æ€»ç»“æœ ==========
    print("\n" + "="*80)
    print("ğŸ“ˆ è¯„æµ‹ç»“æœæ±‡æ€»")
    print("="*80)
    
    if len(results) > 0:
        # åˆ†ç±»ç»Ÿè®¡
        evaluated_datasets = {}  # æœ‰è¯„æµ‹åˆ†æ•°çš„æ•°æ®é›†
        inference_only_datasets = []  # åªåšäº†æ¨ç†çš„æ•°æ®é›†
        
        for dataset_name, result in results.items():
            if result and isinstance(result, dict):
                if result.get('status') == 'inference_only':
                    inference_only_datasets.append(dataset_name)
                elif 'exact_match' in result or 'execution_accuracy' in result:
                    evaluated_datasets[dataset_name] = result
        
        # æ˜¾ç¤ºæœ‰è¯„æµ‹ç»“æœçš„æ•°æ®é›†
        if evaluated_datasets:
            print("\nâœ… å·²å®Œæˆè¯„æµ‹çš„æ•°æ®é›†:\n")
            for dataset_name, result in evaluated_datasets.items():
                emoji = "ğŸ”µ" if DATASET_CONFIGS[dataset_name]['language'] == 'en' else "ğŸŸ¢"
                print(f"{emoji} {dataset_name} æ•°æ®é›†:")
                
                if 'exact_match' in result and result['exact_match'] is not None:
                    print(f"  Exact Match:        {result['exact_match']:.4f} ({result['exact_match']*100:.2f}%)")
                if 'execution_accuracy' in result and result['execution_accuracy'] is not None:
                    print(f"  Execution Accuracy: {result['execution_accuracy']:.4f} ({result['execution_accuracy']*100:.2f}%)")
                
                # æ˜¾ç¤ºéš¾åº¦çº§åˆ«
                has_difficulty = False
                for level in ['easy', 'medium', 'hard', 'extra']:
                    if level in result and result[level] is not None:
                        if not has_difficulty:
                            print("  æŒ‰éš¾åº¦åˆ†å¸ƒ:")
                            has_difficulty = True
                        print(f"    {level.capitalize():6s}: {result[level]:.4f} ({result[level]*100:.2f}%)")
                print()
        
        # è®¡ç®—å¹³å‡åˆ†ï¼ˆä»…é’ˆå¯¹æœ‰è¯„æµ‹ç»“æœçš„æ•°æ®é›†ï¼‰
        if len(evaluated_datasets) >= 2:
            print("\nâ­ å¹³å‡å¾—åˆ† (æ‰€æœ‰å·²è¯„æµ‹æ•°æ®é›†):")
            
            # è®¡ç®— Exact Match å¹³å‡
            em_scores = [res['exact_match'] for res in evaluated_datasets.values() if 'exact_match' in res and res['exact_match'] is not None]
            if em_scores:
                avg_em = sum(em_scores) / len(em_scores)
                print(f"  Exact Match:        {avg_em:.4f} ({avg_em*100:.2f}%)")
            
            # è®¡ç®— Execution Accuracy å¹³å‡
            exec_scores = [res['execution_accuracy'] for res in evaluated_datasets.values() if 'execution_accuracy' in res and res['execution_accuracy'] is not None]
            if exec_scores:
                avg_exec = sum(exec_scores) / len(exec_scores)
                print(f"  Execution Accuracy: {avg_exec:.4f} ({avg_exec*100:.2f}%)")
            
            # è®¡ç®—å„éš¾åº¦çº§åˆ«çš„å¹³å‡åˆ†
            for level in ['easy', 'medium', 'hard', 'extra']:
                level_scores = [res[level] for res in evaluated_datasets.values() if level in res and res[level] is not None]
                if level_scores:
                    if level == 'easy':
                        print("  æŒ‰éš¾åº¦åˆ†å¸ƒ:")
                    avg_level = sum(level_scores) / len(level_scores)
                    print(f"    {level.capitalize():6s}: {avg_level:.4f} ({avg_level*100:.2f}%)")
        
        # æ˜¾ç¤ºåªåšäº†æ¨ç†çš„æ•°æ®é›†
        if inference_only_datasets:
            print("\nğŸ’¡ ä»¥ä¸‹æ•°æ®é›†å·²ç”Ÿæˆé¢„æµ‹SQLï¼ˆæš‚æ— è¯„æµ‹è„šæœ¬ï¼‰:")
            for dataset_name in inference_only_datasets:
                output_file = results[dataset_name].get('output_file', '')
                print(f"  â€¢ {dataset_name}: {output_file}")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆåŒ…å«æ¨¡å‹æ ‡è¯†ï¼Œé¿å…è¦†ç›–ï¼‰
        results_file = os.path.join(args.output_dir, f"evaluation_summary_{model_identifier}.json")
        detailed_results_file = os.path.join(args.output_dir, f"evaluation_detailed_{model_identifier}.txt")
        
        # ä¿å­˜JSONæ ¼å¼çš„ç»“æœï¼ˆåªä¿å­˜æœ‰è¯„æµ‹åˆ†æ•°çš„ç»“æœï¼‰
        with open(results_file, 'w', encoding='utf-8') as f:
            save_results = {k: v for k, v in evaluated_datasets.items()}
            json.dump(save_results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ è¯„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ä¿å­˜è¯¦ç»†çš„æ–‡æœ¬æ ¼å¼ç»“æœ
        with open(detailed_results_file, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("ğŸ“ˆ Text2SQL å¤šæ•°æ®é›†è¯„æµ‹ç»“æœ\n")
            f.write("="*80 + "\n\n")
            
            f.write(f"æµ‹è¯•æ•°æ®é›†: {', '.join(datasets_to_test)}\n")
            f.write(f"æ¨¡å‹ç±»å‹: {args.model_type}\n")
            if args.model_type == 'tuned':
                f.write(f"Checkpoint: {args.checkpoint_dir}\n")
            f.write("\n" + "="*80 + "\n\n")
            
            # è¯¦ç»†ç»“æœ
            if evaluated_datasets:
                f.write("âœ… å·²å®Œæˆè¯„æµ‹çš„æ•°æ®é›†:\n\n")
                for dataset_name, result in evaluated_datasets.items():
                    emoji = "ğŸ”µ" if DATASET_CONFIGS[dataset_name]['language'] == 'en' else "ğŸŸ¢"
                    f.write(f"{emoji} {dataset_name} æ•°æ®é›†:\n")
                    
                    if 'exact_match' in result and result['exact_match'] is not None:
                        f.write(f"  Exact Match:        {result['exact_match']:.4f} ({result['exact_match']*100:.2f}%)\n")
                    else:
                        f.write(f"  Exact Match:        N/A (æ— gold SQLæ–‡ä»¶)\n")
                    
                    if 'execution_accuracy' in result and result['execution_accuracy'] is not None:
                        f.write(f"  Execution Accuracy: {result['execution_accuracy']:.4f} ({result['execution_accuracy']*100:.2f}%)\n")
                    else:
                        f.write(f"  Execution Accuracy: N/A (æ— æ•°æ®åº“æ–‡ä»¶)\n")
                    
                    # æ˜¾ç¤ºéš¾åº¦çº§åˆ«
                    has_difficulty = False
                    for level in ['easy', 'medium', 'hard', 'extra']:
                        if level in result and result[level] is not None:
                            if not has_difficulty:
                                f.write("  æŒ‰éš¾åº¦åˆ†å¸ƒ:\n")
                                has_difficulty = True
                            f.write(f"    {level.capitalize():6s}: {result[level]:.4f} ({result[level]*100:.2f}%)\n")
                    f.write("\n")
                
                # å¹³å‡åˆ†
                if len(evaluated_datasets) >= 2:
                    f.write("\n" + "="*80 + "\n")
                    f.write("â­ å¹³å‡å¾—åˆ† (æ‰€æœ‰å·²è¯„æµ‹æ•°æ®é›†):\n\n")
                    
                    # è®¡ç®— Exact Match å¹³å‡
                    em_scores = [res['exact_match'] for res in evaluated_datasets.values() if 'exact_match' in res and res['exact_match'] is not None]
                    if em_scores:
                        avg_em = sum(em_scores) / len(em_scores)
                        f.write(f"  Exact Match:        {avg_em:.4f} ({avg_em*100:.2f}%)\n")
                    
                    # è®¡ç®— Execution Accuracy å¹³å‡
                    exec_scores = [res['execution_accuracy'] for res in evaluated_datasets.values() if 'execution_accuracy' in res and res['execution_accuracy'] is not None]
                    if exec_scores:
                        avg_exec = sum(exec_scores) / len(exec_scores)
                        f.write(f"  Execution Accuracy: {avg_exec:.4f} ({avg_exec*100:.2f}%)\n")
                    
                    # è®¡ç®—å„éš¾åº¦çº§åˆ«çš„å¹³å‡åˆ†
                    for level in ['easy', 'medium', 'hard', 'extra']:
                        level_scores = [res[level] for res in evaluated_datasets.values() if level in res and res[level] is not None]
                        if level_scores:
                            if level == 'easy':
                                f.write("  æŒ‰éš¾åº¦åˆ†å¸ƒ:\n")
                            avg_level = sum(level_scores) / len(level_scores)
                            f.write(f"    {level.capitalize():6s}: {avg_level:.4f} ({avg_level*100:.2f}%)\n")
            
            # åªåšäº†æ¨ç†çš„æ•°æ®é›†
            if inference_only_datasets:
                f.write("\n" + "="*80 + "\n")
                f.write("ğŸ’¡ ä»¥ä¸‹æ•°æ®é›†å·²ç”Ÿæˆé¢„æµ‹SQLï¼ˆæš‚æ— è¯„æµ‹è„šæœ¬ï¼‰:\n")
                for dataset_name in inference_only_datasets:
                    output_file = results[dataset_name].get('output_file', '')
                    f.write(f"  â€¢ {dataset_name}: {output_file}\n")
            
            f.write("\n" + "="*80 + "\n")
            f.write("âœ… å…¨æµç¨‹ç»“æŸï¼\n")
        
        print(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {detailed_results_file}")
    
    # æ¸…ç†æ•°æ®åº“æ„å»ºå™¨
    if db_builder is not None:
        # ä¸è‡ªåŠ¨æ¸…ç†ï¼Œä¿ç•™æ•°æ®åº“ä»¥ä¾¿åç»­ä½¿ç”¨
        print(f"\nğŸ’¾ ä¸´æ—¶æ•°æ®åº“ä¿ç•™åœ¨: {db_builder.temp_dir}")
        print(f"   å¦‚éœ€æ¸…ç†ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤è¯¥ç›®å½•")
    
    print("\nâœ… å…¨æµç¨‹ç»“æŸï¼")

if __name__ == "__main__":
    main()
